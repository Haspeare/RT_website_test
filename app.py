# app.py - è»Šæµè¾¨è­˜ç³»çµ±åŠŸèƒ½æ¨¡çµ„
import os
import cv2
import numpy as np
from PIL import Image
import io
import time
from collections import defaultdict
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service

# ================= TrafficDetector =================
class TrafficDetector:
    def __init__(self):
        self.model = None
        self.model_type = "onnx"
        self.traffic_stats = defaultdict(int)
        self.load_model()

    def load_model(self):
        """è¼‰å…¥ ONNX æ¨¡å‹"""
        print("=" * 50)
        print("æ­£åœ¨è¼‰å…¥è»Šæµè¾¨è­˜æ¨¡å‹...")
        print("=" * 50)

        onnx_path = "model.onnx"
        if os.path.exists(onnx_path):
            try:
                import onnxruntime as ort
                self.model = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])
                print("âœ… æˆåŠŸè¼‰å…¥ ONNX æ¨¡å‹!")
                print(f"æ¨¡å‹è¼¸å…¥: {[inp.name for inp in self.model.get_inputs()]}")
                print(f"æ¨¡å‹è¼¸å‡º: {[out.name for out in self.model.get_outputs()]}")
            except Exception as e:
                print(f"âŒ ONNX æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
                self.model = None
        else:
            print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ: {onnx_path}")
            self.model = None

        print("=" * 50)

    def detect_objects(self, image, confidence_threshold=0.5):
        """æª¢æ¸¬ç‰©ä»¶"""
        if self.model is None:
            return []

        try:
            # è½‰æ›å½±åƒ
            if isinstance(image, Image.Image):
                frame = np.array(image)
            else:
                frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            h, w = frame.shape[:2]

            # å‰è™•ç†
            input_image = cv2.resize(frame, (640, 640))
            input_image = input_image.astype(np.float32) / 255.0
            input_image = input_image.transpose(2, 0, 1)
            input_image = np.expand_dims(input_image, axis=0)

            # æº–å‚™è¼¸å…¥
            inputs = {}
            for inp in self.model.get_inputs():
                if inp.name == "images":
                    inputs["images"] = input_image
                elif inp.name == "orig_target_sizes":
                    inputs["orig_target_sizes"] = np.array([[640, 640]], dtype=np.int64)

            # æ¨¡å‹æ¨ç†
            outputs = self.model.run(None, inputs)

            # è§£æè¼¸å‡º
            try:
                out_infos = self.model.get_outputs()
                name_to_output = {out_infos[i].name: outputs[i] for i in range(len(out_infos))}

                def squeeze_batch(arr):
                    arr_np = np.array(arr)
                    if arr_np.ndim >= 3 and arr_np.shape[0] == 1:
                        return arr_np[0]
                    if arr_np.ndim == 2 and arr_np.shape[0] == 1:
                        return arr_np[0]
                    return arr_np

                boxes = name_to_output.get("boxes")
                labels = name_to_output.get("labels")
                scores = name_to_output.get("scores")

                if boxes is not None:
                    boxes = squeeze_batch(boxes)
                if labels is not None:
                    labels = squeeze_batch(labels)
                if scores is not None:
                    scores = squeeze_batch(scores)

                if boxes is None or labels is None or scores is None:
                    if len(outputs) >= 3:
                        if boxes is None:
                            boxes = squeeze_batch(outputs[1])
                        if labels is None:
                            labels = squeeze_batch(outputs[2])
                        if scores is None:
                            scores = squeeze_batch(outputs[0])
                    else:
                        return []
            except Exception as parse_error:
                print(f"è¼¸å‡ºè§£æéŒ¯èª¤: {parse_error}")
                return []

            detections = []
            num_items = min(len(scores), len(labels), boxes.shape[0])

            try:
                use_01 = int(np.max(labels)) <= 1
            except Exception:
                use_01 = True

            scale_x = w / 640.0
            scale_y = h / 640.0
            for i in range(num_items):
                conf = float(scores[i])
                if conf < confidence_threshold:
                    continue

                cls = int(labels[i])
                bx1, by1, bx2, by2 = map(float, boxes[i])
                x1 = int(max(0, min(bx1 * scale_x, w - 1)))
                y1 = int(max(0, min(by1 * scale_y, h - 1)))
                x2 = int(max(0, min(bx2 * scale_x, w - 1)))
                y2 = int(max(0, min(by2 * scale_y, h - 1)))
                if x1 >= x2 or y1 >= y2:
                    continue

                if cls == 3:
                    class_name = "motorcycle"
                else:
                    if use_01:
                        class_name = {0: "motorcycle", 1: "car"}.get(cls, f"class_{cls}")
                    else:
                        class_name = {1: "motorcycle", 2: "car"}.get(cls, f"class_{cls}")

                detections.append({
                    "class_id": cls,
                    "class_name": class_name,
                    "confidence": conf,
                    "bbox": [x1, y1, x2, y2]
                })

            print(f"æª¢æ¸¬åˆ° {len(detections)} å€‹ç‰©ä»¶")
            return detections

        except Exception as e:
            print(f"æª¢æ¸¬éŒ¯èª¤: {e}")
            return []

    def draw_detections(self, image, detections):
        try:
            if isinstance(image, Image.Image):
                frame = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            else:
                frame = image.copy()
            for det in detections:
                x1, y1, x2, y2 = map(int, det["bbox"])
                class_name = det["class_name"]
                conf = det["confidence"]
                if class_name == "car":
                    color = (0, 0, 255)
                elif class_name == "motorcycle":
                    color = (0, 255, 0)
                else:
                    color = (0, 255, 255)
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 1)
            return Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        except Exception as e:
            print(f"ç¹ªè£½æª¢æ¸¬çµæœéŒ¯èª¤: {e}")
            return image

# ================= StreamCapture =================
class StreamCapture:
    def __init__(self):
        """åˆå§‹åŒ–ä½†ä¸ç«‹å³è¨­ç½® Chrome é©…å‹•ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰"""
        self.driver = None
        self._driver_initialized = False

    def setup_driver(self):
        """è¨­ç½® Chrome ç€è¦½å™¨ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰"""
        if self._driver_initialized:
            return

        try:
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– Chrome ç€è¦½å™¨...")
            chrome_options = Options()
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1250")

            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self._driver_initialized = True
            print("âœ… Chrome ç€è¦½å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Chrome ç€è¦½å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            self.driver = None
            self._driver_initialized = False

    def capture_stream(self, force_reload=False):
        """æˆªå–ä¸²æµç•«é¢ï¼ˆåƒ…æˆªå–å½±ç‰‡å…ƒç´ ï¼‰"""
        # å»¶é²åˆå§‹åŒ–ï¼šåªåœ¨ç¬¬ä¸€æ¬¡èª¿ç”¨æ™‚æ‰åˆå§‹åŒ– Chrome
        if not self._driver_initialized:
            self.setup_driver()

        if not self.driver:
            return None

        try:
            # å¦‚æœæ˜¯å¼·åˆ¶é‡æ–°è¼‰å…¥æˆ–é¦–æ¬¡è¼‰å…¥ï¼Œé‡æ–°å–å¾—é é¢
            if force_reload or not hasattr(self, '_page_loaded'):
                print("ğŸ”„ é‡æ–°è¼‰å…¥ä¸²æµé é¢...")
                self.driver.get("https://hls.bote.gov.taipei/live/index.html?id=139")
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                time.sleep(1)
                self._page_loaded = True

            # å˜—è©¦å®šä½ä¸¦æˆªå–å½±ç‰‡å…ƒç´ 
            try:
                # ç­‰å¾…å½±ç‰‡å…ƒç´ è¼‰å…¥
                video_element = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.ID, "video"))
                )
                print("âœ… æ‰¾åˆ°å½±ç‰‡å…ƒç´ ")

                # æ»¾å‹•åˆ°å½±ç‰‡å…ƒç´ ï¼Œç¢ºä¿å®Œæ•´å¯è¦‹
                self.driver.execute_script("arguments[0].scrollIntoView(true);", video_element)
                time.sleep(0.1)

                # ä½¿ç”¨ JavaScript è¨­å®šå½±ç‰‡å…ƒç´ å°ºå¯¸ç‚º 1889x1259 ä¸¦ç¢ºä¿æ’­æ”¾
                self.driver.execute_script("""
                    var video = document.getElementById('video');
                    if (video) {
                        // è¨­å®šå½±ç‰‡å°ºå¯¸
                        video.style.width = '1889px';
                        video.style.height = '1259px';
                        video.width = 1889;
                        video.height = 1259;

                        // ç¢ºä¿å½±ç‰‡æ’­æ”¾
                        if (video.paused) {
                            video.play();
                        }
                    }
                """)
                time.sleep(0.1)

                # ç²å–å½±ç‰‡å…ƒç´ çš„å°ºå¯¸
                size = video_element.size
                location = video_element.location
                print(f"ğŸ“ å½±ç‰‡å…ƒç´ å°ºå¯¸: {size['width']}x{size['height']}, ä½ç½®: ({location['x']}, {location['y']})")

                # æˆªå–å½±ç‰‡å…ƒç´ 
                screenshot = video_element.screenshot_as_png
                image = Image.open(io.BytesIO(screenshot))
                print(f"âœ… æˆªåœ–æˆåŠŸï¼Œå°ºå¯¸: {image.size}")
                return image

            except Exception as video_error:
                print(f"âš ï¸ ç„¡æ³•å®šä½å½±ç‰‡å…ƒç´ : {video_error}")
                print("ğŸ“¸ æ”¹ç‚ºæˆªå–æ•´å€‹é é¢")
                # å¦‚æœæ‰¾ä¸åˆ°å½±ç‰‡å…ƒç´ ï¼Œå‰‡æˆªå–æ•´å€‹é é¢
                screenshot = self.driver.get_screenshot_as_png()
                image = Image.open(io.BytesIO(screenshot))
                return image

        except Exception as e:
            print(f"âŒ ä¸²æµæˆªåœ–å¤±æ•—: {e}")
            return None

    def close(self):
        """é—œé–‰ç€è¦½å™¨"""
        if self.driver:
            self.driver.quit()
